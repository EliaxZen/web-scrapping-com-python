{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:186: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:190: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:186: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:190: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\galva\\AppData\\Local\\Temp\\ipykernel_4744\\2859233655.py:186: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df[\"Preço\"] = df[\"Preço\"].str.replace(\"R\\$\", \"\", regex=False).str.replace(\".\", \"\", regex=False).str.strip()\n",
      "C:\\Users\\galva\\AppData\\Local\\Temp\\ipykernel_4744\\2859233655.py:190: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df[\"Preço\"] = df[\"Preço\"].str.extract(\"(\\d+)\").astype(float)\n",
      "2024-06-04 09:32:47,195 - INFO - Iniciando o processo de scraping.\n",
      "2024-06-04 09:32:49,905 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-2.html (Caused by ProxyError('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002746A6D4380>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente')))\n",
      "2024-06-04 09:32:49,925 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-5.html (Caused by ProxyError('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002746A6D4290>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente')))\n",
      "2024-06-04 09:32:56,644 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-5.html (Caused by ProxyError('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002746A6D49B0>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente')))\n",
      "2024-06-04 09:32:56,645 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-2.html (Caused by ProxyError('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002746A6D4980>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente')))\n",
      "2024-06-04 09:32:57,206 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-1.html (Caused by ProxyError('Unable to connect to proxy', ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002746A6B7F80>, 'Connection to 159.89.49.132 timed out. (connect timeout=10)')))\n",
      "2024-06-04 09:32:57,208 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-4.html (Caused by ProxyError('Unable to connect to proxy', ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002746A6D4170>, 'Connection to 46.101.26.4 timed out. (connect timeout=10)')))\n",
      "2024-06-04 09:32:57,208 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-3.html (Caused by ProxyError('Unable to connect to proxy', ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002746A6B7A70>, 'Connection to 64.225.97.57 timed out. (connect timeout=10)')))\n",
      "2024-06-04 09:33:03,375 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-5.html (Caused by ProxyError('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002746A6D4AD0>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente')))\n",
      "2024-06-04 09:33:05,406 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-2.html (Caused by ProxyError('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002746A6D5730>: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente')))\n",
      "2024-06-04 09:33:11,214 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-4.html (Caused by ProxyError('Unable to connect to proxy', ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002746A6D5400>, 'Connection to 46.101.26.4 timed out. (connect timeout=10)')))\n",
      "2024-06-04 09:33:12,216 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-3.html (Caused by ProxyError('Unable to connect to proxy', ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002746A6D5610>, 'Connection to 64.225.97.57 timed out. (connect timeout=10)')))\n",
      "2024-06-04 09:33:13,213 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-1.html (Caused by ProxyError('Unable to connect to proxy', ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002746A6D5880>, 'Connection to 159.89.49.132 timed out. (connect timeout=10)')))\n",
      "2024-06-04 09:33:18,390 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-6.html (Caused by ProxyError('Unable to connect to proxy', ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002746A6D5EE0>, 'Connection to 64.225.97.57 timed out. (connect timeout=10)')))\n",
      "2024-06-04 09:33:19,417 - WARNING - Erro ao acessar a página: HTTPSConnectionPool(host='www.imovelweb.com.br', port=443): Max retries exceeded with url: /imoveis-aluguel-distrito-federal-pagina-7.html (Caused by ProxyError('Unable to connect to proxy', ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002746A6D63F0>, 'Connection to 46.101.53.59 timed out. (connect timeout=10)')))\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from distrito_federal_setor import setores\n",
    "import concurrent.futures\n",
    "import logging\n",
    "from random import randint, choice\n",
    "from typing import List, Dict\n",
    "\n",
    "# Configurações de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Configurações\n",
    "TEMPO_ESPERA = 3  # Aumenta o tempo de espera entre requisições\n",
    "NUM_PAGINAS = 10\n",
    "URL_BASE = \"https://www.imovelweb.com.br\"\n",
    "ARQUIVO_SAIDA = r\"C:\\Users\\galva\\OneDrive\\Documentos\\GitHub\\web-scrapping-com-python\\base_de_dados_excel\\imovel_web_data_base\\imovel_web_aluguel_df_05_2024.xlsx\"\n",
    "\n",
    "# Lista de User-Agents para rotação\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:87.0) Gecko/20100101 Firefox/87.0\",\n",
    "    # Adicione outros User-Agents conforme necessário\n",
    "]\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": choice(USER_AGENTS),\n",
    "    \"Referer\": \"https://www.imovelweb.com.br/\",\n",
    "}\n",
    "\n",
    "# Lista de proxies reais (testados)\n",
    "PROXIES = [\n",
    "    'http://104.248.63.15:30588',\n",
    "    'http://45.76.176.138:8080',\n",
    "    'http://159.89.49.132:8080',\n",
    "    'http://46.101.26.4:39313',\n",
    "    'http://64.225.8.115:9989',\n",
    "    'http://178.62.193.19:8080',\n",
    "    'http://64.225.97.57:8080',\n",
    "    'http://46.101.53.59:8080',\n",
    "    'http://167.172.236.149:39313',\n",
    "    'http://167.172.236.149:39313',\n",
    "    # Adicione mais proxies conforme necessário\n",
    "]\n",
    "\n",
    "def extrair_setor(titulo: str) -> str:\n",
    "    \"\"\"Extrai o setor a partir do título do imóvel.\"\"\"\n",
    "    palavras = titulo.split()\n",
    "    palavras_upper = [palavra.upper() for palavra in palavras]\n",
    "    for palavra in palavras_upper:\n",
    "        if palavra in setores:\n",
    "            return palavra\n",
    "    return \"OUTRO\"\n",
    "\n",
    "def extrair_tipo(link: str) -> str:\n",
    "    \"\"\"Extrai o tipo de imóvel a partir do link.\"\"\"\n",
    "    tipos = {\n",
    "        \"apartamento\": \"Apartamento\",\n",
    "        \"casa\": \"Casa\",\n",
    "        \"casa-condominio\": \"Casa Condomínio\",\n",
    "        \"galpo\": \"Galpão\",\n",
    "        \"garagem\": \"Garagem\",\n",
    "        \"hotel-flat\": \"Flat\",\n",
    "        \"flat\": \"Flat\",\n",
    "        \"kitnet\": \"Kitnet\",\n",
    "        \"loja\": \"Loja\",\n",
    "        \"loteamento\": \"Loteamento\",\n",
    "        \"lote-terreno\": \"Lote Terreno\",\n",
    "        \"ponto-comercial\": \"Ponto Comercial\",\n",
    "        \"prdio\": \"Prédio\",\n",
    "        \"predio\": \"Prédio\",\n",
    "        \"sala\": \"Sala\",\n",
    "        \"rural\": \"Zona Rural\",\n",
    "        \"lancamento\": \"Lançamento\",\n",
    "        \"lote\": \"Lote/Terreno\",\n",
    "        \"galpao\": \"Galpão\",\n",
    "        \"comercial\": \"Comercial\",\n",
    "        \"fazenda\": \"Fazenda\",\n",
    "        \"chacara\": \"Chácara\",\n",
    "        \"condominio\": \"Condomínio\",\n",
    "        \"kit\": \"Kitnet\",\n",
    "        \"hotel\": \"Hotel\",\n",
    "        \"residencial\": \"Residencial\",\n",
    "    }\n",
    "    for key, value in tipos.items():\n",
    "        if key in link:\n",
    "            return value\n",
    "    return \"OUTROS\"\n",
    "\n",
    "def obter_dados_imovel(imovel: BeautifulSoup) -> Dict[str, str]:\n",
    "    \"\"\"Extrai os dados de um imóvel.\"\"\"\n",
    "    titulo = imovel.find(\"div\", class_=\"LocationAddress-sc-ge2uzh-0 iylBOA postingAddress\")\n",
    "    link = URL_BASE + imovel[\"data-to-posting\"]\n",
    "    subtitulo = imovel.find(\"h2\", attrs={\"data-qa\": \"POSTING_CARD_LOCATION\"})\n",
    "    imobiliaria_element = imovel.find(\"img\", attrs={\"data-qa\": \"POSTING_CARD_PUBLISHER\"})\n",
    "    imobiliaria = imobiliaria_element[\"src\"] if imobiliaria_element else None\n",
    "    preco = imovel.find(\"div\", attrs={\"data-qa\": \"POSTING_CARD_PRICE\"})\n",
    "    condominio = imovel.find(\"div\", attrs={\"data-qa\": \"expensas\"})\n",
    "    metro_area = imovel.find(\"h3\", attrs={\"data-qa\": \"POSTING_CARD_FEATURES\"})\n",
    "    metro = metro_area.find(\"span\") if metro_area else None\n",
    "    quarto_banheiro_vaga = imovel.find(\"h3\", attrs={\"data-qa\": \"POSTING_CARD_FEATURES\"})\n",
    "\n",
    "    quarto = banheiro = vaga = None\n",
    "    if quarto_banheiro_vaga:\n",
    "        lista = quarto_banheiro_vaga.findAll(\"span\")\n",
    "        for item in lista:\n",
    "            texto = item.text.lower()\n",
    "            if \"quartos\" in texto:\n",
    "                quarto = item.text\n",
    "            elif \"ban.\" in texto:\n",
    "                banheiro = item.text\n",
    "            elif \"vaga\" in texto:\n",
    "                vaga = item.text\n",
    "\n",
    "    return {\n",
    "        \"Título\": titulo.text.strip() if titulo else None,\n",
    "        \"Subtítulo\": subtitulo.text.strip() if subtitulo else None,\n",
    "        \"Link\": link,\n",
    "        \"Preço\": preco.text if preco else None,\n",
    "        \"Área\": metro.text.replace(\" m² tot.\", \"\").strip() if metro else None,\n",
    "        \"Quarto\": quarto,\n",
    "        \"Banheiro\": banheiro,\n",
    "        \"Vaga\": vaga,\n",
    "        \"Imobiliária\": imobiliaria,\n",
    "    }\n",
    "\n",
    "def obter_pagina(url: str, session: requests.Session) -> BeautifulSoup:\n",
    "    \"\"\"Obtém o conteúdo de uma página.\"\"\"\n",
    "    headers = HEADERS.copy()\n",
    "    headers[\"User-Agent\"] = choice(USER_AGENTS)  # Rotaciona o User-Agent a cada requisição\n",
    "    proxy = {\"http\": choice(PROXIES), \"https\": choice(PROXIES)}  # Seleciona um proxy aleatório\n",
    "    for _ in range(3):  # Tentar 3 vezes\n",
    "        try:\n",
    "            resposta = session.get(url, headers=headers, proxies=proxy, timeout=10)  # Adicionado timeout\n",
    "            resposta.raise_for_status()\n",
    "            return BeautifulSoup(resposta.content, \"html.parser\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.warning(f\"Erro ao acessar a página: {e}\")\n",
    "            time.sleep(TEMPO_ESPERA + randint(1, 3))  # Espera um tempo aleatório\n",
    "    return None\n",
    "\n",
    "def obter_lista_de_imoveis(paginas: int = NUM_PAGINAS, tempo_espera: int = TEMPO_ESPERA) -> List[Dict[str, str]]:\n",
    "    \"\"\"Obtém a lista de imóveis de várias páginas.\"\"\"\n",
    "    lista_de_imoveis = []\n",
    "    urls_adicionados = set()\n",
    "\n",
    "    with requests.Session() as session:\n",
    "        session.headers.update(HEADERS)\n",
    "        urls = [f\"{URL_BASE}/imoveis-aluguel-distrito-federal-pagina-{pagina}.html\" for pagina in range(1, paginas + 1)]\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            future_to_url = {executor.submit(obter_pagina, url, session): url for url in urls}\n",
    "            for future in concurrent.futures.as_completed(future_to_url):\n",
    "                url = future_to_url[future]\n",
    "                try:\n",
    "                    site = future.result()\n",
    "                    if site:\n",
    "                        imoveis = site.findAll(\"div\", attrs={\"data-qa\": \"posting PROPERTY\"})\n",
    "                        for imovel in imoveis:\n",
    "                            dados_imovel = obter_dados_imovel(imovel)\n",
    "                            if (\n",
    "                                dados_imovel[\"Título\"]\n",
    "                                and dados_imovel[\"Subtítulo\"]\n",
    "                                and dados_imovel[\"Preço\"]\n",
    "                                and dados_imovel[\"Área\"]\n",
    "                                and \"Sob Consulta\" not in dados_imovel[\"Preço\"]\n",
    "                                and dados_imovel[\"Link\"] not in urls_adicionados\n",
    "                            ):\n",
    "                                lista_de_imoveis.append(dados_imovel)\n",
    "                                urls_adicionados.add(dados_imovel[\"Link\"])\n",
    "                            else:\n",
    "                                logging.info(\"Imóvel ignorado devido a dados ausentes ou preço 'Sob Consulta'\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Erro ao processar página {url}: {e}\")\n",
    "\n",
    "                time.sleep(tempo_espera + randint(1, 3))  # Espera um tempo aleatório\n",
    "    return lista_de_imoveis\n",
    "\n",
    "def processar_dados(lista_de_imoveis: List[Dict[str, str]]) -> pd.DataFrame:\n",
    "    \"\"\"Processa os dados e retorna um DataFrame.\"\"\"\n",
    "    df = pd.DataFrame(lista_de_imoveis)\n",
    "    df[\"Área\"] = df[\"Área\"].str.replace(\" m²\", \"\", regex=False)\n",
    "    df[\"Preço\"] = df[\"Preço\"].str.replace(\"R\\$\", \"\", regex=False).str.replace(\".\", \"\", regex=False).str.strip()\n",
    "    df[\"Setor\"] = df[\"Título\"].apply(extrair_setor)\n",
    "    df[\"Tipo\"] = df[\"Link\"].apply(extrair_tipo)\n",
    "    df = df[df[\"Setor\"].isin(setores)]\n",
    "    df[\"Preço\"] = df[\"Preço\"].str.extract(\"(\\d+)\").astype(float)\n",
    "    df[\"Área\"] = df[\"Área\"].astype(float)\n",
    "    df[\"Preço_m2\"] = df[\"Preço\"] / df[\"Área\"]\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    logging.info(\"Iniciando o processo de scraping.\")\n",
    "    lista_de_imoveis = obter_lista_de_imoveis()\n",
    "    logging.info(f\"Total de imóveis coletados: {len(lista_de_imoveis)}\")\n",
    "    df = processar_dados(lista_de_imoveis)\n",
    "    df.to_excel(ARQUIVO_SAIDA, index=False)\n",
    "    logging.info(f\"Dados salvos em {ARQUIVO_SAIDA}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
